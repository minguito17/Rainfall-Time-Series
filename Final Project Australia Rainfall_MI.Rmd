---
title: "ADS506 Project Australia Rainfall Forecast"
author: "Marinela Inguito, Jose Guarneros, Robert Marriott"

output: pdf_document
---

```{r warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyr)
library(tsibble)
library(tseries)
library(feasts)
library(fpp3)
library(corrplot)
library(patchwork)
library(fable)
library(Metrics)
library(xgboost)
library(fastDummies)
library(caret)
library(forecast)
```

## Importing the Data

```{r}
weather_data <- read.csv("weatherAUS.csv")
str(weather_data$Date)
```

## Preview of Data

```{r}
str(weather_data)      # Structure of the dataset
summary(weather_data)  # Summary statistics for each column
head(weather_data)     
```

## Data Preprocessing
## Convert Date Column

```{r}
weather_data$Date <- as.Date(weather_data$Date, format = "%Y-%m-%d")
str(weather_data$Date)
```
```{r}

weather_data <- weather_data |>
  mutate(
    Date = as.Date(Date),  # Convert Date to proper format
    AvgWindSpeed = (WindSpeed9am + WindSpeed3pm) / 2,
    AvgHumidity = (Humidity9am + Humidity3pm) / 2,
    AvgPressure = (Pressure9am + Pressure3pm) / 2,
    AvgCloud = (Cloud9am + Cloud3pm) / 2,
    AvgTemp = (Temp9am + Temp3pm) / 2
  ) %>%
  group_by(Date, Location) |>
  summarize(
    AvgWindSpeed = mean(AvgWindSpeed, na.rm = TRUE),
    AvgHumidity = mean(AvgHumidity, na.rm = TRUE),
    AvgPressure = mean(AvgPressure, na.rm = TRUE),
    AvgCloud = mean(AvgCloud, na.rm = TRUE),
    AvgTemp = mean(AvgTemp, na.rm = TRUE),
    MinTemp = mean(MinTemp, na.rm = TRUE),
    MaxTemp = mean(MaxTemp, na.rm = TRUE),
    Rainfall = sum(Rainfall, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Rained = ifelse(Rainfall > 0, 1, 0)  # Binary column: 1 if Rainfall > 0, else 0
  ) 

df <- weather_data

weather_data |>
  as_tsibble(index = Date, key = Location)


head(weather_data)
str(weather_data)

```

```{r}
```

## Arrange the date

```{r}
ggplot(weather_data, aes(x = Date, y = Rainfall)) +
  geom_line() +
  labs(title = "Rainfall by Date", x = "Date", y = "Mean Rainfall (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.margin = margin(1, 1, 1, 1, "cm"))
```
```{r}
# Numeric features
numeric_features <- weather_data[c("AvgWindSpeed", "AvgHumidity", "AvgPressure", "AvgCloud", "MinTemp", "MaxTemp", "Rainfall", "AvgTemp")]

# Calculate the correlation matrix for all numeric columns
cor_matrix <- cor(numeric_features, use = "complete.obs")

# Correlation matrix
corrplot(cor_matrix, 
         method = "color",  
         col = colorRampPalette(c("blue", "white", "red"))(200),  
         title = "Correlation Matrix Heatmap",  
         tl.cex = 0.8,  
         cl.cex = 0.8,  
         addCoef.col = NULL,  
         number.cex = 0.8,  
         diag = FALSE,  
         tl.col = "black")  
```

## Scatter plot features vs Rainfall

```{r}
# List of features to plot against Rainfall
features <- c("AvgWindSpeed", "AvgHumidity", "AvgPressure", "AvgCloud", "MinTemp", "MaxTemp", "Rainfall", "AvgTemp")

# Check for missing values in these columns and impute the mean if there are any
weather_data[features] <- suppressWarnings(weather_data[features] |>
  mutate(across(
    all_of(features),  
    ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)  
  )))

# Verify that missing values have been handled
colSums(is.na(weather_data[features]))

# Create scatter plots for each feature vs Rainfall
for (feature in features) {
  plot <- ggplot(weather_data, aes_string(x = feature, y = "Rainfall")) +
    geom_point() +
    labs(title = paste("Scatter Plot of", feature, "vs Rainfall"),
         x = feature,
         y = "Rainfall") +
    theme_minimal()
  print(plot)
}
```

## Relevant Columns Filtered

```{r}
## Relevant features based on corr plot above: 
## "MinTemp", "WindGustSpeed", "WindSpeed9am", "WindSpeed3pm", "Humidity9am", "Humidity3pm", "Cloud9am", "Cloud3pm"


weather_data_mod <- weather_data |>
  select(Date, Location, Rainfall, MinTemp, AvgWindSpeed, AvgHumidity, AvgPressure, AvgCloud, MinTemp, MaxTemp, Rainfall, AvgTemp, Rained)
```

## Specific Cities Filtered

```{r}
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")
weather_data_mod <- weather_data_mod |> filter(Location %in% cities)
```

## Data Cleaning
## Handle Missing Values

```{r}
colSums(is.na(weather_data_mod))
```

## Drop rows with missing Values from Rainfall or RainTomorrow

```{r}
weather_data_mod <- weather_data_mod |> drop_na(Rainfall)
```

## Impute other columns using the mean

```{r}
weather_data_mod$MinTemp[is.na(weather_data_mod$MinTemp)] <- mean(weather_data_mod$MinTemp, na.rm = TRUE)

```

## Verify Data Types

```{r}
str(weather_data_mod)  # Confirm all variables have correct data types
colnames(weather_data_mod)
```

## Aggregate Weekly Rainfall


weather_data_weekly <- weather_data_processed %>%
  mutate(Week = floor_date(ymd(Date), "week")) %>%
  group_by(Location, Week) %>%
  summarize(
    WeeklyRainfall = sum(Rainfall, na.rm = TRUE),
    AvgWeeklyWindSpeed = mean(AvgWindSpeed, na.rm = TRUE),
    AvgWeeklyHumidity = mean(AvgHumidity, na.rm = TRUE),
    AvgWeeklyPressure = mean(AvgPressure, na.rm = TRUE),
    AvgWeeklyCloud = mean(AvgCloud, na.rm = TRUE),
    AvgWeeklyTemp = mean(AvgTemp, na.rm = TRUE),
    MinWeeklyTemp = mean(MinTemp, na.rm = TRUE),
    MaxWeeklyTemp = mean(MaxTemp, na.rm = TRUE),
    .groups = "drop"
  )

# View the processed weekly data
#print(weather_data_weekly)



## Differencing for stationarity

```{r}
weather_data_mod <- weather_data_mod |>
  group_by(Location) |>
  mutate(Diff_Rainfall = c(NA, diff(Rainfall))) |>
  ungroup()
```

## Remove rows with N/A

```{r}
weather_data_mod <- weather_data_mod |>
  drop_na()

head(weather_data_mod)
```
## Time Series Plot

```{r}
sydney_weather <- weather_data_processed |>
  filter(Location == "Sydney") |>
  select(Date, Rainfall) |>
  drop_na(Rainfall)

sydney_weather_tsibble <- sydney_weather |>
  mutate(Date = as.Date(Date)) |>
  as_tsibble(index = Date)

sydney_weather_tsibble |>
  autoplot(Rainfall) +
  labs(title = "Rainfall Time Series for Sydney",
       x = "Time",
       y = "Rainfall (mm)") +
  theme_minimal()
```



## Split data by city

```{r}
weather_data_splits <- split(weather_data_mod, weather_data_mod$Location)

```

## Perform decomposition of each city next

```{r}
sydney_data <- weather_data_splits$Sydney
sydney_ts <- sydney_data |>
  as_tsibble(index = Date) |>
  fill_gaps()

```

# Perform Decomposition Sydney

```{r}
sydney_decomposition <- sydney_ts |>
  model(STL(Rainfall ~ season(window = 13))) |>
  components()
```

# Plot Decomposition

```{r}
autoplot(sydney_decomposition) +
  labs(title = "STL Decomposition of Rainfall in Sydney", y = "")
```

# acf plot Sydney

```{r}
acf_plot_Sydney <- sydney_ts |>
  ACF(Rainfall) |>
  autoplot() +
  labs(title = "ACF of Rainfall in Sydney", y = "ACF", x = "Lag") +
  theme_minimal()

acf_plot_Sydney
```




## Splitting Data?

```{r}
max(weather_data_mod$Date)
min(weather_data_mod$Date)

# Function to filter and deselect
filter_data <- function(data, start_date, end_date) {
  data %>%
    filter(Date >= as.Date(start_date) & Date <= as.Date(end_date)) %>%
    select(Location, Date, Rainfall, MinTemp, AvgWindSpeed, AvgHumidity, AvgPressure, AvgCloud, MinTemp, MaxTemp, Rainfall, AvgTemp, Rained)
}

# Apply function to create train and test sets
train <- filter_data(df, "2008-02-03", "2015-06-24")
test <- filter_data(df, "2015-06-25", "2017-06-25")

```

## splitting by city
```{r}
## Training and test sets for each city (Perth, Darwin, Sydney, and Melbourne)
train_perth <- train |> 
  filter(Location == "Perth")
train_darwin <- train |> 
  filter(Location == "Darwin")
train_sydney <- train |> 
  filter(Location == "Sydney")
train_melbourne <- train |> 
  filter(Location == "Melbourne")

test_perth <- test |> 
  filter(Location == "Perth")
test_darwin <- test |> 
  filter(Location == "Darwin")
test_sydney <- test |> 
  filter(Location == "Sydney")
test_melbourne <- test |> 
  filter(Location == "Melbourne")

head(train_darwin)
```

```{r}
generate_acf_plot <- function(data, location, title_prefix = "ACF of Rainfall") {
  data %>%
    filter(Location == location) %>%
    select(Date, Rainfall) %>%
    drop_na(Rainfall) %>%
    mutate(Date = as.Date(Date)) %>%
    as_tsibble(index = Date) %>%
    fill_gaps(Rainfall = NA) %>%
    ACF(Rainfall) %>%
    autoplot() +
    labs(
      title = paste(title_prefix, "for", location),
      x = "Lag",
      y = "ACF"
    ) +
    theme_minimal()
}

acf_train_perth <- generate_acf_plot(train, "Perth", "ACF of Rainfall (Train)")
acf_train_darwin <- generate_acf_plot(train, "Darwin", "ACF of Rainfall (Train)")
acf_train_sydney <- generate_acf_plot(train, "Sydney", "ACF of Rainfall (Train)")
acf_train_melbourne <- generate_acf_plot(train, "Melbourne", "ACF of Rainfall (Train)")

(acf_train_perth | acf_train_darwin) /
(acf_train_sydney | acf_train_melbourne)


```


```{r}
acf_test_perth <- generate_acf_plot(test, "Perth", "ACF of Rainfall (Test)")
acf_test_darwin <- generate_acf_plot(test, "Darwin", "ACF of Rainfall (Test)")
acf_test_sydney <- generate_acf_plot(test, "Sydney", "ACF of Rainfall (Test)")
acf_test_melbourne <- generate_acf_plot(test, "Melbourne", "ACF of Rainfall (Test)")

(acf_test_perth | acf_test_darwin) /
(acf_test_sydney | acf_test_melbourne)
```

## Exploratory Data Analysis?

```{r}

fit_xgboost <- function(train_data, test_data) {
  # Prepare the data
  train_matrix <- prepare_xgb_data(train_data)
  test_matrix <- prepare_xgb_data(test_data)
  
  # Target variable
  train_labels <- as.numeric(train_data$Rained)
  test_labels <- as.numeric(test_data$Rained)
  
  # Fit XGBoost model
  model <- xgboost(
    data = train_matrix,
    label = train_labels,
    nrounds = 100,
    objective = "binary:logistic",
    verbose = 0
  )
  
  # Predict on the test set
  test_predictions <- predict(model, test_matrix)
  test_predictions_binary <- ifelse(test_predictions > 0.5, 1, 0)
  
  # Generate confusion matrix
  confusion <- confusionMatrix(
    factor(test_predictions_binary),
    factor(test_labels),
    positive = "1"
  )
  
  return(list(model = model, confusion = confusion))
}

# Locations and datasets
train_test_data <- list(
  Perth = list(train = train_perth, test = test_perth),
  Darwin = list(train = train_darwin, test = test_darwin),
  Sydney = list(train = train_sydney, test = test_sydney),
  Melbourne = list(train = train_melbourne, test = test_melbourne)
)

# Fit models and generate confusion matrices
results <- lapply(names(train_test_data), function(location) {
  cat("\nProcessing", location, "...\n")
  train_data <- train_test_data[[location]]$train
  test_data <- train_test_data[[location]]$test
  fit_xgboost(train_data, test_data)
})

# Print confusion matrices for each location
names(results) <- names(train_test_data)
lapply(names(results), function(location) {
  cat("\nConfusion Matrix for", location, ":\n")
  print(results[[location]]$confusion)
})


```
```{r}
head(test_darwin)
```

## Splitting by city
```{r}
str(train_perth)
```

## ARIMA/SARIMA
```{r}
# Initialize an empty list to store results
arima_results <- list()

# Loop through each city
for (city in names(weather_data_splits)) {
  # Extract the city's data
  city_data <- weather_data_splits[[city]] |>
    as_tsibble(index = Date)
  
  # Ensure no missing values
  city_data <- city_data |>
    mutate(Rainfall = replace_na(Rainfall, 0))  # Replace NAs with zeros or use interpolation
  
  # Fit ARIMA model
  arima_model <- auto.arima(city_data$Rainfall, seasonal = TRUE)
  
  # Forecast next 12 months
  forecast_arima <- forecast(arima_model, h = 12)
  
  # Store results in the list
  arima_results[[city]] <- list(
    model = arima_model,
    forecast = forecast_arima
  )
}

# Print summaries of models for each city
for (city in names(arima_results)) {
  cat("\nCity:", city, "\n")
  print(summary(arima_results[[city]]$model))
}

# Create a combined forecast plot
forecast_plots <- lapply(names(arima_results), function(city) {
  forecast_data <- arima_results[[city]]$forecast
  autoplot(forecast_data) +
    labs(title = paste("ARIMA Forecast for", city, "Rainfall"),
         x = "Time",
         y = "Rainfall (mm)") +
    theme_minimal()
})

# Combine and display all plots using patchwork
Reduce(`/`, forecast_plots)
```

## Linear Regression
```{r}
# Initialize an empty list to store results
linear_regression_results <- list()

# Loop through each city
for (city in names(weather_data_splits)) {
  # Extract the city's data
  city_data <- weather_data_splits[[city]]
  
  # Ensure no missing values in predictors
  predictors <- c("MinTemp", "AvgWindSpeed", "AvgHumidity", "AvgPressure", "AvgCloud", "MaxTemp")
  city_data[predictors] <- city_data[predictors] |>
    mutate(across(everything(), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))  # Impute missing values
  
  # Fit linear regression model
  lm_model <- lm(Rainfall ~ MinTemp + AvgWindSpeed + AvgHumidity + AvgPressure + AvgCloud + MaxTemp, data = city_data)
  
  # Store the model and summary in the results list
  linear_regression_results[[city]] <- list(
    model = lm_model,
    summary = summary(lm_model)
  )
}

# Print summaries of models for each city
for (city in names(linear_regression_results)) {
  cat("\nCity:", city, "\n")
  print(linear_regression_results[[city]]$summary)
}


# Create prediction plots for each city
prediction_plots <- lapply(names(weather_data_splits), function(city) {
  # Extract city data and model
  city_data <- weather_data_splits[[city]]
  lm_model <- linear_regression_results[[city]]$model
  
  # Add predicted values to the city data
  city_data$PredictedRainfall <- predict(lm_model, newdata = city_data)
  
  # Generate plot
  ggplot(city_data, aes(x = Rainfall, y = PredictedRainfall)) +
    geom_point(alpha = 0.6) +
    geom_abline(intercept = 0, slope = 1, color = "red") +
    labs(title = paste("Actual vs. Predicted Rainfall for", city),
         x = "Actual Rainfall (mm)",
         y = "Predicted Rainfall (mm)") +
    theme_minimal()
})

# Combine and display all plots using patchwork
Reduce(`/`, prediction_plots)
```



