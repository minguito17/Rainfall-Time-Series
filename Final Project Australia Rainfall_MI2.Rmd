---
title: "ADS506 Project Australia Rainfall Forecast"
author: "Marinela Inguito, Jose Guarneros, Robert Marriott"

output: pdf_document
---

```{r warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyr)
library(tsibble)
library(tseries)
library(feasts)
library(fpp3)
library(corrplot)
library(patchwork)
library(fable)
library(Metrics)
library(xgboost)
library(fastDummies)
library(caret)
library(forecast)
library(kableExtra)
library(purrr)
library(knitr)
```

## Importing the Data

```{r}
weather_data <- read.csv("weatherAUS.csv")
str(weather_data$Date)
```

## Preview of Data

```{r}
str(weather_data)      # Structure of the dataset
summary(weather_data)  # Summary statistics for each column
head(weather_data)     
```

## Data Preprocessing

## Convert Date Column

```{r}
weather_data$Date <- as.Date(weather_data$Date, format = "%Y-%m-%d")
#weather_data <- as_tsibble(weather_data, index = Date)
```

```{r}
weather_data_monthly <- weather_data |>
  mutate(
    Date = as.Date(Date),  # Convert Date to proper format
    year_month = format(Date, "%Y-%m"),  # Extract Year-Month for grouping
    AvgWindSpeed = (WindSpeed9am + WindSpeed3pm) / 2,
    AvgHumidity = (Humidity9am + Humidity3pm) / 2,
    AvgPressure = (Pressure9am + Pressure3pm) / 2,
    AvgCloud = (Cloud9am + Cloud3pm) / 2,
    AvgTemp = (Temp9am + Temp3pm) / 2
  ) |>
  group_by(Location, year_month) |>  # Group by Location and year_month
  summarize(
    AvgWindSpeed = mean(AvgWindSpeed, na.rm = TRUE),
    AvgHumidity = mean(AvgHumidity, na.rm = TRUE),
    AvgPressure = mean(AvgPressure, na.rm = TRUE),
    AvgCloud = mean(AvgCloud, na.rm = TRUE),
    AvgTemp = mean(AvgTemp, na.rm = TRUE),
    MinTemp = mean(MinTemp, na.rm = TRUE),
    MaxTemp = mean(MaxTemp, na.rm = TRUE),
    Rainfall = sum(Rainfall, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(
    Rained = ifelse(Rainfall > 0, 1, 0)  # Binary column: 1 if Rainfall > 0, else 0
  ) 
```

```{r}
weather_data_monthly$year_month <- yearmonth(weather_data_monthly$year_month)
class(weather_data_monthly$year_month)
```

```{r}
weather_data_ts <- weather_data_monthly |>
  as_tsibble(index = year_month, key = Location)

head(weather_data_ts)
```

```{r}
# Create the time series plot
weather_data_ts$Rainfall <- as.numeric(weather_data_ts$Rainfall)
rainfall_ts <- ts(weather_data_ts$Rainfall, start = c(2008, 1), end = c(2017, 12), frequency = 12)

# Use autoplot() to plot the time series
autoplot(rainfall_ts) +
  labs(title = "Rainfall Time Series", x = "Year-Month", y = "Rainfall (mm)") +
  theme_minimal()

```

## Correlation matrix

```{r}
# Numeric features
numeric_features <- weather_data_ts[c("AvgWindSpeed", "AvgHumidity", "AvgPressure", "AvgCloud", "MinTemp", "MaxTemp", "Rainfall", "AvgTemp")]

# Ensure all selected features are numeric
numeric_features <- sapply(numeric_features, as.numeric)

# Calculate the correlation matrix for all numeric columns
cor_matrix <- cor(numeric_features, use = "complete.obs")

# Generate the correlation heatmap
corrplot(cor_matrix, 
         method = "color",  # Use colors to represent correlation values
         col = colorRampPalette(c("blue", "white", "red"))(200),  # Color scale
         title = "Correlation Matrix Heatmap",  
         addCoef.col = "black",  # Add correlation coefficients on the plot
         number.cex = 0.8,  # Size of the coefficients
         diag = FALSE,  # Hide diagonal
         tl.col = "black",  # Text label color
         tl.cex = 0.8,  # Text label size
         mar = c(0, 0, 1, 0))  # Margins around the plot
```

## Scatter plot features vs Rainfall

```{r}
# List of features to plot against Rainfall
features <- c("AvgWindSpeed", "AvgHumidity", "AvgPressure", "AvgCloud", "MinTemp", "MaxTemp", "Rainfall", "AvgTemp")

# Check for missing values in these columns and impute the mean if there are any
weather_data_ts[features] <- suppressWarnings(weather_data_ts[features] |>
  mutate(across(
    all_of(features),  
    ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)  
  )))

# Verify that missing values have been handled
colSums(is.na(weather_data_ts[features]))

# Create scatter plots for each feature vs Rainfall
for (feature in features) {
  plot <- ggplot(weather_data_ts, aes_string(x = feature, y = "Rainfall")) +
    geom_point() +
    labs(title = paste("Scatter Plot of", feature, "vs Rainfall"),
         x = feature,
         y = "Rainfall") +
    theme_minimal()
  print(plot)
}
```

## Data Cleaning

# Handle Missing Values

```{r}
colSums(is.na(weather_data_monthly))
```

# Impute missing values

```{r}
weather_data_monthly$AvgWindSpeed[is.na(weather_data_monthly$AvgWindSpeed)] <- mean(weather_data_monthly$AvgWindSpeed, na.rm = TRUE)
weather_data_monthly$MinTemp[is.na(weather_data_monthly$MinTemp)] <- mean(weather_data_monthly$MinTemp, na.rm = TRUE)
weather_data_monthly$AvgHumidity[is.na(weather_data_monthly$AvgHumidity)] <- mean(weather_data_monthly$AvgHumidity, na.rm = TRUE)
weather_data_monthly$AvgPressure[is.na(weather_data_monthly$AvgPressure)] <- mean(weather_data_monthly$AvgPressure, na.rm = TRUE)
weather_data_monthly$AvgCloud[is.na(weather_data_monthly$AvgCloud)] <- mean(weather_data_monthly$AvgCloud, na.rm = TRUE)
weather_data_monthly$AvgTemp[is.na(weather_data_monthly$AvgTemp)] <- mean(weather_data_monthly$AvgTemp, na.rm = TRUE)
weather_data_monthly$MaxTemp[is.na(weather_data_monthly$MaxTemp)] <- mean(weather_data_monthly$MaxTemp, na.rm = TRUE)
colSums(is.na(weather_data_monthly))
```

# Split the data into train and test sets

```{r}
set.seed(123)

train_data <- weather_data_monthly |> 
  filter(year_month >= yearmonth("2007 Nov") & year_month <= yearmonth("2015 Jun"))

test_data <- weather_data_monthly |> 
  filter(year_month >= yearmonth("2015 Jul") & year_month <= yearmonth("2017 Jun"))
```

# Time Series Plots for four cities, decompose, differencing

```{r}
# Initialize an empty list to store results for each city
city_results <- list()

# Split the data into train and test sets
train_data <- weather_data_monthly |> 
  filter(year_month >= yearmonth("2007 Nov") & year_month <= yearmonth("2015 Jun"))

test_data <- weather_data_monthly |> 
  filter(year_month >= yearmonth("2015 Jul") & year_month <= yearmonth("2017 Jun"))

# Time Series Plots for four cities, decompose, differencing
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

for (city in cities) {
  # Filter data for the current city
  city_train_data <- train_data |> filter(Location == city)
  
  # Convert to tsibble and create a time series object
  city_train_tsibble <- city_train_data |> 
    as_tsibble(index = year_month, key = Location)
  
  # Ensure Rainfall is a numeric vector and create a time series object
  rainfall_ts <- ts(city_train_tsibble$Rainfall, frequency = 12)
  
  # Time Series Plot
  ts_plot <- city_train_tsibble |> 
    autoplot(Rainfall) +
    ggtitle(paste("Rainfall Time Series for", city)) +
    theme_minimal()
  
  print(ts_plot)  # Display the time series plot
  
  # Stationarity check using Augmented Dickey-Fuller Test
  adf_result <- adf.test(rainfall_ts)
  
  cat("ADF Test for", city, "\n")
  print(adf_result)
  
  # If the time series is non-stationary, apply differencing once
  if (adf_result$p.value >= 0.05) {
    cat("Conclusion: The time series for", city, "is non-stationary. Applying differencing.\n\n")
    
    # Apply differencing to make the series stationary (only once)
    diff_rainfall_ts <- diff(rainfall_ts)
    
    # Store differenced series in the results list
    city_results[[city]]$diff_rainfall_ts <- diff_rainfall_ts
    
    # Re-perform the ADF Test on the differenced series
    adf_result_diff <- adf.test(diff_rainfall_ts)
    
    cat("ADF Test after differencing for", city, "\n")
    print(adf_result_diff)
    
    if (adf_result_diff$p.value < 0.05) {
      cat("Conclusion: The differenced series for", city, "is stationary.\n\n")
      
      # Apply decomposition on the differenced series
      city_decomposition <- stl(diff_rainfall_ts, s.window = "periodic")
      
      # Plot decomposition
      decomposition_plot <- autoplot(city_decomposition) +
        ggtitle(paste("STL Decomposition for", city, "After Differencing")) +
        theme_minimal()
      
      print(decomposition_plot)  # Display the decomposition plot
    } else {
      cat("Conclusion: The differenced series for", city, "is still non-stationary. Additional differencing may be needed.\n\n")
    }
  } else {
    cat("Conclusion: The time series for", city, "is stationary.\n\n")
    
    # If stationary, apply decomposition directly
    city_decomposition <- stl(rainfall_ts, s.window = "periodic")
    
    # Plot decomposition
    decomposition_plot <- autoplot(city_decomposition) +
      ggtitle(paste("STL Decomposition for", city)) +
      theme_minimal()
    
    print(decomposition_plot)  # Display the decomposition plot
  }
  
  # Store results for the current city
  city_results[[city]] <- list(
    time_series_plot = ts_plot,
    decomposed = city_decomposition
  )
}
```

## ACF and PACF for ARIMA Model Identification

```{r}
# Define the four cities of interest
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

# Loop through the four cities to generate ACF and PACF plots
for (city in cities) {
  # Filter data for the current city
  city_train_data <- train_data |> filter(Location == city)
  
  # Check if data for the city exists
  if (nrow(city_train_data) == 0) {
    message(paste("No data available for", city, "- Skipping."))
    next
  }
  
  # Convert to tsibble and create a time series object
  city_train_tsibble <- city_train_data |> 
    as_tsibble(index = year_month, key = Location)
  
  # Ensure Rainfall is a numeric vector and create a time series object
  rainfall_ts <- ts(city_train_tsibble$Rainfall, frequency = 12)
  
  # Apply differencing (only once)
  diff_rainfall_ts <- diff(rainfall_ts)
  
  # ACF Plot for Differenced Rainfall for the current city
  acf(diff_rainfall_ts, lag.max = 20, main = paste("ACF of Differenced Rainfall for", city))
  
  # PACF Plot for Differenced Rainfall for the current city
  pacf(diff_rainfall_ts, lag.max = 20, main = paste("PACF of Differenced Rainfall for", city))
}
```

## ARIMA MODELLING

```{r}
set.seed(123)

# Initialize an empty list to store ARIMA models for each city
city_results <- list()

# Create a data frame to store the ARIMA model details for each city
arima_summary_df <- data.frame(
  City = character(),
  ARIMA_Order = character(),
  AIC = numeric(),
  BIC = numeric(),
  Coefficients = character(),
  stringsAsFactors = FALSE
)

# Loop through the cities to apply ARIMA modeling
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

for (city in cities) {
  # Filter data for the current city
  city_train_data <- train_data |> filter(Location == city)
  
  # Check if data for the city exists
  if (nrow(city_train_data) == 0) {
    message(paste("No data available for", city, "- Skipping."))
    next
  }
  
  # Convert to tsibble and create a time series object
  city_train_tsibble <- city_train_data |> 
    as_tsibble(index = year_month, key = Location)
  
  # Ensure Rainfall is a numeric vector and create a time series object
  rainfall_ts <- ts(city_train_tsibble$Rainfall, frequency = 12)
  
  # Fit an ARIMA model directly to the stationary data
  arima_model <- auto.arima(rainfall_ts)
  
  # Extract ARIMA order (p, d, q)
  arima_order <- paste(arima_model$arma[1], arima_model$arma[6], arima_model$arma[2], sep = ",")
  
  # Extract AIC and BIC
  aic_value <- arima_model$aic
  bic_value <- arima_model$bic
  
  # Extract coefficients and convert to string
  coeffs <- paste(names(arima_model$coef), round(arima_model$coef, 4), collapse = ", ")
  
  # Store the ARIMA summary in the data frame
  arima_summary_df <- rbind(arima_summary_df, data.frame(
    City = city,
    ARIMA_Order = arima_order,
    AIC = aic_value,
    BIC = bic_value,
    Coefficients = coeffs
  ))
  
  # Store the ARIMA model for the current city
  city_results[[city]] <- list(
    arima_model = arima_model
  )
}

# Display the ARIMA summary table using kable
kable(arima_summary_df, caption = "ARIMA Model Summary for Each City") |>
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  ) |>
  column_spec(2, bold = TRUE, border_right = TRUE) |>
  column_spec(3:4, width = "10em") |>
  column_spec(5, width = "20em", extra_css = "word-wrap: break-word;")
```

## Assess ARIMA Forecast Accuracy on Test Data

```{r}
set.seed(123)

# List of cities
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

# Create a data frame to store forecast accuracy results
forecast_table <- data.frame()

for (city in cities) {
  # Filter data for the current city
  city_train_data <- train_data |> filter(Location == city)
  city_test_data <- test_data |> filter(Location == city)
  
  # Ensure data exists for the city
  if (nrow(city_train_data) == 0 || nrow(city_test_data) == 0) {
    message(paste("No data available for", city, "- Skipping."))
    next
  }
  
  # Convert training data to a time series object
  rainfall_train_ts <- ts(city_train_data$Rainfall, frequency = 12)
  
  # Fit an ARIMA model to the training data
  arima_model <- auto.arima(rainfall_train_ts)
  
  # Forecast on the test data range
  forecast_steps <- nrow(city_test_data)
  arima_forecast <- forecast(arima_model, h = forecast_steps)
  
  # Calculate forecast accuracy using actual test data
  test_actuals <- city_test_data$Rainfall
  forecast_accuracy <- accuracy(arima_forecast, test_actuals)
  
  # Extract key metrics and add to the table
  forecast_table <- rbind(
    forecast_table,
    data.frame(
      City = city,
      AIC = round(arima_model$aic, 2),
      BIC = round(arima_model$bic, 2),
      RMSE = round(forecast_accuracy["Test set", "RMSE"], 3),
      MAE = round(forecast_accuracy["Test set", "MAE"], 3),
      MAPE = round(forecast_accuracy["Test set", "MAPE"], 2)
    )
  )
}

# Create a styled table with wider columns
forecast_table %>%
  kbl(
    col.names = c("City", "AIC", "BIC", "RMSE", "MAE", "MAPE (%)"),
    caption = "Forecast Accuracy Metrics for Each City",
    align = "lccccr"
  ) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    position = "center"
  ) %>%
  column_spec(2, width = "3cm") %>% # Widen AIC column
  column_spec(3, width = "3cm") %>% # Widen BIC column
  column_spec(4:6, width = "4cm")  # Widen RMSE, MAE, columns
```

# Perth had best ARIMA results, plot forecasted and actual values

```{r}
set.seed(123)

# Filter data for Perth
city_train_data <- train_data |> filter(Location == "Perth")
city_test_data <- test_data |> filter(Location == "Perth")

# Convert training data to a time series object
rainfall_train_ts <- ts(city_train_data$Rainfall, frequency = 12)

# Fit an ARIMA model to the training data
arima_model <- auto.arima(rainfall_train_ts)

# Forecast on the test data range
forecast_steps <- nrow(city_test_data)
arima_forecast <- forecast(arima_model, h = forecast_steps)

# Create a data frame for the forecast, actual values, and confidence intervals
forecast_df <- data.frame(
  Date = city_test_data$year_month,
  Forecast = arima_forecast$mean,
  Actual = city_test_data$Rainfall,
  Lower80 = arima_forecast$lower[, 1],  # 80% CI lower bound
  Upper80 = arima_forecast$upper[, 1],  # 80% CI upper bound
  Lower90 = arima_forecast$lower[, 2],  # 90% CI lower bound
  Upper90 = arima_forecast$upper[, 2]   # 90% CI upper bound
)

# Plot the forecasted vs actual values with confidence intervals
suppressWarnings(
ggplot(forecast_df, aes(x = Date)) +
  geom_ribbon(aes(ymin = Lower90, ymax = Upper90), fill = "lightblue", alpha = 0.2) +  # 90% Confidence intervals
  geom_ribbon(aes(ymin = Lower80, ymax = Upper80), fill = "lightblue", alpha = 0.4) +  # 80% Confidence intervals
  geom_line(aes(y = Forecast, color = "Forecast"), size = 1) +                   # Forecast line
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +                       # Actual data line
  labs(title = "ARIMA Forecast with 80% and 90% Confidence Intervals for Perth",
       x = "Date", y = "Rainfall (mm)") +
  scale_color_manual(values = c("Forecast" = "blue", "Actual" = "black")) +       # Set colors
  theme_minimal() +
  theme(legend.title = element_blank(), legend.position = "bottom")             # Position legend
)
```

## Modelling


## XGBoost

```{r}
set.seed(123)

# Loop through each city to train and assess the model
# List of cities
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

# Create a data frame to store forecast accuracy results
forecast_results <- data.frame()

# Create a list to store predictions for plotting later
predictions_list <- list()

# Loop through each city to train and assess the model
for (city in cities) {
  
  # Filter data for the current city
  city_train_data <- train_data |> filter(Location == city)
  city_test_data <- test_data |> filter(Location == city)
  
  # Ensure data exists for the city
  if (nrow(city_train_data) == 0 || nrow(city_test_data) == 0) {
    message(paste("No data available for", city, "- Skipping."))
    next
  }
  
  # Prepare the features (use all columns except 'Rainfall' for features)
  train_features <- city_train_data %>%
    select(-Location, -Rainfall, -year_month) %>% 
    as.matrix()  # Convert to matrix format for XGBoost

  test_features <- city_test_data %>%
    select(-Location, -Rainfall, -year_month) %>% 
    as.matrix()  # Convert to matrix format for XGBoost
  
  # Prepare the target variable (Rainfall)
  train_target <- city_train_data$Rainfall
  test_target <- city_test_data$Rainfall
  
  # Convert data to xgboost-friendly format
  dtrain <- xgb.DMatrix(data = train_features, label = train_target)
  dtest <- xgb.DMatrix(data = test_features, label = test_target)
  
  # Set parameters for XGBoost
  params <- list(
    booster = "gbtree",  # Tree-based model
    objective = "reg:squarederror",  # Regression task
    eval_metric = "rmse",  # Root mean square error as the evaluation metric
    max_depth = 6,  # Maximum depth of the trees
    eta = 0.3,  # Learning rate
    nthread = 2  # Number of threads
  )
  
  # Train the model
  xgboost_model <- xgb.train(
    params = params, 
    data = dtrain, 
    nrounds = 100,  # Number of boosting rounds
    watchlist = list(train = dtrain, test = dtest),  # Watch the performance on both train and test sets
    verbose = 0  # Suppress progress during training
  )
  
  # Make predictions on the test set
  xgboost_predictions <- predict(xgboost_model, newdata = dtest)
  
  # Calculate RMSE, MAE, and MAPE for the current city
  rmse_value <- sqrt(mean((test_target - xgboost_predictions)^2))
  mae_value <- mean(abs(test_target - xgboost_predictions))
  mape_value <- mean(abs((test_target - xgboost_predictions) / test_target)) * 100
  
  # Store the results in the data frame
  forecast_results <- rbind(
    forecast_results,
    data.frame(
      City = city,
      RMSE = round(rmse_value, 3),
      MAE = round(mae_value, 3),
      MAPE = round(mape_value, 2)
    )
  )
  
  # Store the predictions for plotting later
  predictions_list[[city]] <- list(
    actual = test_target,
    predicted = xgboost_predictions,
    date = city_test_data$year_month
  )
}

# Print the forecast accuracy results
print(forecast_results)

# Extract the predictions for Melbourne from predictions_list
melbourne_predictions <- predictions_list[["Melbourne"]]

# Create the plot
ggplot() +
  geom_line(aes(x = melbourne_predictions$date, y = melbourne_predictions$actual, color = "Actual"), size = 1) +
  geom_line(aes(x = melbourne_predictions$date, y = melbourne_predictions$predicted, color = "Predicted"), size = 1) +
  labs(title = "XGBoost Prediction vs Actual Rainfall for Melbourne",
       x = "Date", y = "Rainfall (mm)") +
  scale_color_manual(values = c("Actual" = "black", "Predicted" = "blue")) +
  theme_minimal() +
  theme(legend.title = element_blank(), legend.position = "bottom")

```

# Melbourne had best results on XGBoost, plot forecasted and actual values



## Linear Regression

```{r}
set.seed(123)

# Loop through each city to train and assess the model
# List of cities
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

# Create a data frame to store forecast accuracy results
forecast_results <- data.frame()

# Create a list to store predictions for plotting later
predictions_list <- list()

# Loop through each city to train and assess the model
for (city in cities) {
  
  # Filter data for the current city
  city_train_data <- train_data |> filter(Location == city)
  city_test_data <- test_data |> filter(Location == city)
  
  # Ensure data exists for the city
  if (nrow(city_train_data) == 0 || nrow(city_test_data) == 0) {
    message(paste("No data available for", city, "- Skipping."))
    next
  }
  
  # Prepare the features (use all columns except 'Rainfall' for features)
  train_features <- city_train_data %>%
    select(-Location, -Rainfall, -year_month)  # Remove 'Location' and 'Rainfall' for features
  
  test_features <- city_test_data %>%
    select(-Location, -Rainfall, -year_month)  # Remove 'Location' and 'Rainfall' for features
  
  # Prepare the target variable (Rainfall)
  train_target <- city_train_data$Rainfall
  test_target <- city_test_data$Rainfall
  
  # Train the Linear Regression model
  linear_model <- lm(Rainfall ~ ., data = city_train_data %>% select(-Location, -year_month))
  
  # Make predictions on the test set
  linear_predictions <- predict(linear_model, newdata = test_features)
  
  # Calculate RMSE, MAE, and MAPE for the current city
  rmse_value <- sqrt(mean((test_target - linear_predictions)^2))
  mae_value <- mean(abs(test_target - linear_predictions))
  mape_value <- mean(abs((test_target - linear_predictions) / test_target)) * 100
  
  # Store the results in the data frame
  forecast_results <- rbind(
    forecast_results,
    data.frame(
      City = city,
      RMSE = round(rmse_value, 3),
      MAE = round(mae_value, 3),
      MAPE = round(mape_value, 2)
    )
  )
  
  # Store the predictions for plotting later
  predictions_list[[city]] <- list(
    actual = test_target,
    predicted = linear_predictions,
    date = city_test_data$year_month
  )
}

# Print the forecast accuracy results
print(forecast_results)
```

# Linear Regression: Melbourne had best result

# plot forecasted and actual values

```{r}
# Extract the predictions for Melbourne from predictions_list
melbourne_predictions <- predictions_list[["Melbourne"]]

# Create the plot
ggplot() +
  geom_line(aes(x = melbourne_predictions$date, y = melbourne_predictions$actual, color = "Actual"), size = 1) +
  geom_line(aes(x = melbourne_predictions$date, y = melbourne_predictions$predicted, color = "Predicted"), size = 1) +
  labs(title = "Linear Regression Prediction vs Actual Rainfall for Melbourne",
       x = "Date", y = "Rainfall (mm)") +
  scale_color_manual(values = c("Actual" = "grey", "Predicted" = "blue")) +
  theme_minimal() +
  theme(legend.title = element_blank(), legend.position = "bottom")
```


## Plot Table Summary of Models


```{r}
# Initialize an empty data frame to store performance metrics
performance_table <- data.frame(
  Model = character(),
  City = character(),
  RMSE = numeric(),
  MAE = numeric(),
  stringsAsFactors = FALSE
)

# Function to add metrics to the performance table
add_metrics <- function(model_name, city, rmse_value, mae_value) {
  performance_table <<- rbind(
    performance_table,
    data.frame(
      Model = model_name,
      City = city,
      RMSE = round(rmse_value, 3),
      MAE = round(mae_value, 3),
      stringsAsFactors = FALSE
    )
  )
}

# List of cities to process
cities <- c("Sydney", "Perth", "Darwin", "Melbourne")

# Add ARIMA results
for (city in cities) {
  if (city %in% names(city_results) && !is.null(city_results[[city]]$arima_model)) {
    city_test_data <- test_data |> filter(Location == city)
    forecast_steps <- nrow(city_test_data)
    if (forecast_steps > 0) {
      arima_model <- city_results[[city]]$arima_model
      arima_forecast <- forecast(arima_model, h = forecast_steps)
      test_actuals <- city_test_data$Rainfall
      rmse_value <- sqrt(mean((test_actuals - arima_forecast$mean)^2, na.rm = TRUE))
      mae_value <- mean(abs(test_actuals - arima_forecast$mean), na.rm = TRUE)
      add_metrics("ARIMA", city, rmse_value, mae_value)
    }
  }
}

# Manually add correct XGBoost results
xgboost_metrics <- list(
  Sydney = list(RMSE = 83.202, MAE = 52.196),
  Perth = list(RMSE = 33.023, MAE = 24.536),
  Darwin = list(RMSE = 88.583, MAE = 60.525),
  Melbourne = list(RMSE = 26.023, MAE = 17.362)
)

for (city in cities) {
  if (city %in% names(xgboost_metrics)) {
    metrics <- xgboost_metrics[[city]]
    add_metrics("XGBoost", city, metrics$RMSE, metrics$MAE)
  }
}

# Add Linear Regression results dynamically
for (city in cities) {
  if (city %in% names(predictions_list)) {
    linear_predictions <- predictions_list[[city]]$predicted
    linear_actuals <- predictions_list[[city]]$actual
    if (!is.null(linear_predictions) && !is.null(linear_actuals)) {
      rmse_value <- sqrt(mean((linear_actuals - linear_predictions)^2, na.rm = TRUE))
      mae_value <- mean(abs(linear_actuals - linear_predictions), na.rm = TRUE)
      add_metrics("Linear Regression", city, rmse_value, mae_value)
    }
  }
}

# Display the performance table
library(kableExtra)
performance_table %>%
  kbl(
    col.names = c("Model", "City", "RMSE", "MAE"),
    caption = "Performance Metrics Across Models for Selected Cities",
    align = "lccc"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )

```




